{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGOjst5N4wOGiwWja4HnM3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/es162008087/proyecto_de_investigacion/blob/master/Tesis_Maestria_Alvaro_Toriz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Detección de Spam con Aprendizaje Automático"
      ],
      "metadata": {
        "id": "nqklNb_BZ1UH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFLmtklBaI_p",
        "outputId": "72f84fd2-484a-458b-d5cf-454bd4dc0fbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 02:28:01--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron1.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1802573 (1.7M) [application/x-gzip]\n",
            "Saving to: ‘enron1.tar.gz’\n",
            "\n",
            "enron1.tar.gz       100%[===================>]   1.72M   930KB/s    in 1.9s    \n",
            "\n",
            "2023-03-24 02:28:03 (930 KB/s) - ‘enron1.tar.gz’ saved [1802573/1802573]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron2.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O3j1LJdccJH",
        "outputId": "7a880ca0-5322-4cb5-cdf3-249d1abe442d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 02:28:37--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron2.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2905627 (2.8M) [application/x-gzip]\n",
            "Saving to: ‘enron2.tar.gz’\n",
            "\n",
            "enron2.tar.gz       100%[===================>]   2.77M  1.30MB/s    in 2.1s    \n",
            "\n",
            "2023-03-24 02:28:39 (1.30 MB/s) - ‘enron2.tar.gz’ saved [2905627/2905627]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron3.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0x0FBMPclC2",
        "outputId": "eed2761b-fc8e-4be3-9f74-c2631b931c5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 02:31:08--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron3.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4569634 (4.4M) [application/x-gzip]\n",
            "Saving to: ‘enron3.tar.gz’\n",
            "\n",
            "enron3.tar.gz       100%[===================>]   4.36M  1.78MB/s    in 2.5s    \n",
            "\n",
            "2023-03-24 02:31:11 (1.78 MB/s) - ‘enron3.tar.gz’ saved [4569634/4569634]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron4.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4f2w7kwdJ4W",
        "outputId": "cf604829-4ef3-4de5-b2c1-00d3d58810f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 02:31:36--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron4.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2533019 (2.4M) [application/x-gzip]\n",
            "Saving to: ‘enron4.tar.gz’\n",
            "\n",
            "enron4.tar.gz       100%[===================>]   2.42M  1.13MB/s    in 2.1s    \n",
            "\n",
            "2023-03-24 02:31:38 (1.13 MB/s) - ‘enron4.tar.gz’ saved [2533019/2533019]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron5.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuK6pQGadQkG",
        "outputId": "4ddb6443-3760-4ddc-8e92-368783e58a44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 02:31:52--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron5.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2396886 (2.3M) [application/x-gzip]\n",
            "Saving to: ‘enron5.tar.gz’\n",
            "\n",
            "enron5.tar.gz       100%[===================>]   2.29M  1.18MB/s    in 1.9s    \n",
            "\n",
            "2023-03-24 02:31:54 (1.18 MB/s) - ‘enron5.tar.gz’ saved [2396886/2396886]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron6.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkJ68cHwdUh2",
        "outputId": "cb77fdd1-4fa2-4da0-87af-b36c2022ea72"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 02:32:07--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron6.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3137204 (3.0M) [application/x-gzip]\n",
            "Saving to: ‘enron6.tar.gz’\n",
            "\n",
            "enron6.tar.gz       100%[===================>]   2.99M  1.26MB/s    in 2.4s    \n",
            "\n",
            "2023-03-24 02:32:09 (1.26 MB/s) - ‘enron6.tar.gz’ saved [3137204/3137204]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3HqIP2OdYKQ",
        "outputId": "077b444a-15ac-4e2d-ed93-c1c2159927f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enron1.tar.gz  enron3.tar.gz  enron5.tar.gz  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "enron2.tar.gz  enron4.tar.gz  enron6.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Recorrer los archivos .tar.gz de la raíz y descomprimirlos\n",
        "archivos_extraidos = []\n",
        "for archivo in os.listdir(\"/\"):\n",
        "    if archivo.endswith(\".tar.gz\"):\n",
        "        print(f\"Descomprimiendo {archivo} ...\")\n",
        "        try:\n",
        "            resultado = subprocess.run([\"tar\", \"xf\", os.path.join(\"/\", archivo)], check=True, stderr=subprocess.PIPE)\n",
        "            print(f\"{archivo} descomprimido exitosamente.\")\n",
        "            archivos_extraidos.append(archivo)\n",
        "        except subprocess.CalledProcessError as error:\n",
        "            print(f\"No se puede descomprimir {archivo}: {error.stderr.decode('utf-8').strip()}\")\n",
        "        \n",
        "        print(f\"Contenido de la carpeta actual: {os.listdir('/')}\")\n",
        "            \n",
        "print(\"Archivos extraídos:\")\n",
        "print(archivos_extraidos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uGMfDridaF1",
        "outputId": "73dc938c-f93c-4cbc-af45-31487d3444bb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos extraídos:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKYVkAP1fooc",
        "outputId": "d424a519-ddb7-4b59-96af-b6d7e72ae4f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enron1.tar.gz  enron3.tar.gz  enron5.tar.gz  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "enron2.tar.gz  enron4.tar.gz  enron6.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf enron1.tar.gz"
      ],
      "metadata": {
        "id": "FyyvCA8xf4rP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPG2R2i2ifKH",
        "outputId": "7c13be9a-94d5-4851-8074-2fd3331afd23"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34menron1\u001b[0m/        enron2.tar.gz  enron4.tar.gz  enron6.tar.gz\n",
            "enron1.tar.gz  enron3.tar.gz  enron5.tar.gz  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Recorrer los archivos .tar.gz de la raíz y descomprimirlos\n",
        "archivos_extraidos = []\n",
        "for archivo in os.listdir(\"/\"):\n",
        "    if archivo.endswith(\".tar.gz\"):\n",
        "        print(f\"Descomprimiendo {archivo} ...\")\n",
        "        try:\n",
        "            resultado = subprocess.run([\"tar\", \"xf\", os.path.join(\"/\", archivo)], check=True, stderr=subprocess.PIPE)\n",
        "            print(f\"{archivo} descomprimido exitosamente.\")\n",
        "            archivos_extraidos.append(archivo)\n",
        "        except subprocess.CalledProcessError as error:\n",
        "            print(f\"No se puede descomprimir {archivo}: {error.stderr.decode('utf-8').strip()}\")\n",
        "        \n",
        "        print(f\"Contenido de la carpeta actual: {os.listdir('/')}\")\n",
        "            \n",
        "print(\"Archivos extraídos:\")\n",
        "print(archivos_extraidos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MfZ-XhSigoR",
        "outputId": "4f6fa950-2b45-402b-8a58-580029e5c505"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos extraídos:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGBBmAfXjJWE",
        "outputId": "9a8cec07-214e-40ec-f7e3-6c2690daf2c1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34menron1\u001b[0m/        enron2.tar.gz  enron4.tar.gz  enron6.tar.gz\n",
            "enron1.tar.gz  enron3.tar.gz  enron5.tar.gz  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "archivos_a_extraer = [\"enron1.tar.gz\", \"enron2.tar.gz\", \"enron3.tar.gz\", \"enron4.tar.gz\", \"enron5.tar.gz\", \"enron6.tar.gz\"]\n",
        "\n",
        "archivos_extraidos = []\n",
        "\n",
        "for archivo in archivos_a_extraer:\n",
        "    nombre_carpeta = archivo.replace(\".tar.gz\", \"\")\n",
        "    \n",
        "    if not os.path.exists(nombre_carpeta):\n",
        "        print(f\"Descomprimiendo {archivo} ...\")\n",
        "        try:\n",
        "            resultado = subprocess.run([\"tar\", \"xf\", archivo], check=True, stderr=subprocess.PIPE)\n",
        "            print(f\"{archivo} descomprimido exitosamente.\")\n",
        "            archivos_extraidos.append(archivo)\n",
        "        except subprocess.CalledProcessError as error:\n",
        "            print(f\"No se puede descomprimir {archivo}: {error.stderr.decode('utf-8').strip()}\")\n",
        "        \n",
        "        print(f\"Contenido de la carpeta actual: {os.listdir()}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"{archivo} ya ha sido extraído antes. Saltando...\")\n",
        "            \n",
        "print(\"Archivos extraídos:\")\n",
        "print(archivos_extraidos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpUr2Pg6jMCS",
        "outputId": "8666c2c1-d5d1-4fdf-c085-06ddac28fe10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enron1.tar.gz ya ha sido extraído antes. Saltando...\n",
            "Descomprimiendo enron2.tar.gz ...\n",
            "enron2.tar.gz descomprimido exitosamente.\n",
            "Contenido de la carpeta actual: ['.config', 'enron2.tar.gz', 'enron4.tar.gz', 'enron6.tar.gz', 'enron3.tar.gz', 'enron5.tar.gz', 'enron1.tar.gz', 'enron2', 'enron1', 'sample_data']\n",
            "Descomprimiendo enron3.tar.gz ...\n",
            "enron3.tar.gz descomprimido exitosamente.\n",
            "Contenido de la carpeta actual: ['.config', 'enron2.tar.gz', 'enron4.tar.gz', 'enron6.tar.gz', 'enron3.tar.gz', 'enron5.tar.gz', 'enron1.tar.gz', 'enron2', 'enron1', 'enron3', 'sample_data']\n",
            "Descomprimiendo enron4.tar.gz ...\n",
            "enron4.tar.gz descomprimido exitosamente.\n",
            "Contenido de la carpeta actual: ['.config', 'enron2.tar.gz', 'enron4.tar.gz', 'enron4', 'enron6.tar.gz', 'enron3.tar.gz', 'enron5.tar.gz', 'enron1.tar.gz', 'enron2', 'enron1', 'enron3', 'sample_data']\n",
            "Descomprimiendo enron5.tar.gz ...\n",
            "enron5.tar.gz descomprimido exitosamente.\n",
            "Contenido de la carpeta actual: ['.config', 'enron2.tar.gz', 'enron4.tar.gz', 'enron4', 'enron6.tar.gz', 'enron3.tar.gz', 'enron5.tar.gz', 'enron1.tar.gz', 'enron2', 'enron5', 'enron1', 'enron3', 'sample_data']\n",
            "Descomprimiendo enron6.tar.gz ...\n",
            "enron6.tar.gz descomprimido exitosamente.\n",
            "Contenido de la carpeta actual: ['.config', 'enron2.tar.gz', 'enron6', 'enron4.tar.gz', 'enron4', 'enron6.tar.gz', 'enron3.tar.gz', 'enron5.tar.gz', 'enron1.tar.gz', 'enron2', 'enron5', 'enron1', 'enron3', 'sample_data']\n",
            "Archivos extraídos:\n",
            "['enron2.tar.gz', 'enron3.tar.gz', 'enron4.tar.gz', 'enron5.tar.gz', 'enron6.tar.gz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1hIDYyEjzC-",
        "outputId": "b2dbc48e-7cba-41ed-bfc8-a2f2d756a53d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34menron1\u001b[0m/        enron2.tar.gz  \u001b[01;34menron4\u001b[0m/        enron5.tar.gz  \u001b[01;34msample_data\u001b[0m/\n",
            "enron1.tar.gz  \u001b[01;34menron3\u001b[0m/        enron4.tar.gz  \u001b[01;34menron6\u001b[0m/\n",
            "\u001b[01;34menron2\u001b[0m/        enron3.tar.gz  \u001b[01;34menron5\u001b[0m/        enron6.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls enron1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D67dX8wKj2eJ",
        "outputId": "4b27a4a7-f192-4942-9dde-767501b02c2f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mham\u001b[0m/  \u001b[01;34mspam\u001b[0m/  \u001b[01;32mSummary.txt\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat enron1/Summary.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6EnGKiakaUB",
        "outputId": "ec2b20a5-9507-43d7-b923-31207218f35b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legitimate\r\n",
            "----------\r\n",
            "- Owner: farmer-d\r\n",
            "- Total number: 3672 emails\r\n",
            "- Date of first email: 1999-12-10\r\n",
            "- Date of last email: 2002-01-11\r\n",
            "- Similars deletion: No\r\n",
            "- Encoding: No\r\n",
            "\r\n",
            "\r\n",
            "Spam\r\n",
            "----\r\n",
            "- Owner: GP\r\n",
            "- Total number: 1500 emails\r\n",
            "- Date of first email: 2003-12-18\r\n",
            "- Date of last email: 2005-09-06\r\n",
            "- Similars deletion: No\r\n",
            "- Encoding: No\r\n",
            "\r\n",
            "Spam:Legitimate rate = 1:3\r\n",
            "Total number of emails (legitimate + spam): 5975\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import chardet\n",
        "\n",
        "data = {'subject': [], 'body': [], 'classification': []}\n",
        "\n",
        "root_dir = ''\n",
        "\n",
        "for i in range(1, 7):\n",
        "    enron_dir = os.path.join(root_dir, f'enron{i}')\n",
        "    spam_dir = os.path.join(enron_dir, 'spam')\n",
        "    ham_dir = os.path.join(enron_dir, 'ham')\n",
        "\n",
        "    for dir_path, dir_names, file_names in os.walk(spam_dir):\n",
        "        for file_name in file_names:\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                result = chardet.detect(f.read())\n",
        "                encoding = result['encoding']\n",
        "            with open(file_path, 'r', encoding=encoding, errors='ignore') as f:\n",
        "                subject = f.readline().strip()\n",
        "                body = f.read().strip()\n",
        "            data['subject'].append(subject)\n",
        "            data['body'].append(body)\n",
        "            data['classification'].append('spam')\n",
        "\n",
        "    for dir_path, dir_names, file_names in os.walk(ham_dir):\n",
        "        for file_name in file_names:\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                result = chardet.detect(f.read())\n",
        "                encoding = result['encoding']\n",
        "            with open(file_path, 'r', encoding=encoding, errors='ignore') as f:\n",
        "                subject = f.readline().strip()\n",
        "                body = f.read().strip()\n",
        "            data['subject'].append(subject)\n",
        "            data['body'].append(body)\n",
        "            data['classification'].append('ham')\n",
        "\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "P75SrzeDkh8f"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_spam = df[df['classification'] == 'spam'].shape[0]\n",
        "num_ham = df[df['classification'] == 'ham'].shape[0]\n",
        "\n",
        "print(f'Total mensajes spam: {num_spam}')\n",
        "print(f'Total mensajes ham: {num_ham}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwXJdWVxmp31",
        "outputId": "524ac365-6db1-4100-de25-80796fafb461"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total mensajes spam: 17171\n",
            "Total mensajes ham: 16545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Separar los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['body'], df['classification'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenización de palabras y creación de vectores de características\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Inicializar el modelo de Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Entrenar el modelo utilizando los datos de entrenamiento vectorizados\n",
        "nb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Evaluar el modelo utilizando los datos de prueba\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "accuracy = nb_model.score(X_test_vectorized, y_test)\n",
        "\n",
        "# Calcular la precisión del modelo\n",
        "print(f\"La precisión del modelo de Naive Bayes es de: {accuracy:.3f}\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predecir las clases de los datos de prueba\n",
        "y_pred = nb_model.predict(X_test_vectorized)\n",
        "\n",
        "# Imprimir un informe con las diferentes métricas de desempeño\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Informe de métricas de desempeño:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRFel4YQn2nY",
        "outputId": "e320eb37-d208-4dfd-f18a-136de668fa5f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La precisión del modelo de Naive Bayes es de: 0.986\n",
            "La precisión del modelo de Naive Bayes es de: 0.986\n",
            "Informe de métricas de desempeño:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.99      3374\n",
            "        spam       0.98      0.99      0.99      3370\n",
            "\n",
            "    accuracy                           0.99      6744\n",
            "   macro avg       0.99      0.99      0.99      6744\n",
            "weighted avg       0.99      0.99      0.99      6744\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1dLcc5NVqhrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}