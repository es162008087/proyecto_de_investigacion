{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3/jx9DaDVonGkHGb3nqYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/es162008087/proyecto_de_investigacion/blob/master/Tesis_Maestria_Alvaro_Toriz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detección de Spam con Aprendizaje Automático"
      ],
      "metadata": {
        "id": "eL76RbfsuZnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "bcEupCptW67i"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFLmtklBaI_p",
        "outputId": "918d1c79-59b2-4d01-dc20-c560509abfe2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 01:50:51--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron1.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1802573 (1.7M) [application/x-gzip]\n",
            "Saving to: ‘enron1.tar.gz.1’\n",
            "\n",
            "enron1.tar.gz.1     100%[===================>]   1.72M   906KB/s    in 1.9s    \n",
            "\n",
            "2023-03-31 01:50:53 (906 KB/s) - ‘enron1.tar.gz.1’ saved [1802573/1802573]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron2.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O3j1LJdccJH",
        "outputId": "7f7c7b1c-6715-4764-bfe0-96b06a6481a1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 01:50:53--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron2.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2905627 (2.8M) [application/x-gzip]\n",
            "Saving to: ‘enron2.tar.gz.1’\n",
            "\n",
            "enron2.tar.gz.1     100%[===================>]   2.77M  1.14MB/s    in 2.4s    \n",
            "\n",
            "2023-03-31 01:50:55 (1.14 MB/s) - ‘enron2.tar.gz.1’ saved [2905627/2905627]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron3.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0x0FBMPclC2",
        "outputId": "2b69b8d0-d4b9-415e-d092-4ae4e284b451"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 01:50:56--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron3.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4569634 (4.4M) [application/x-gzip]\n",
            "Saving to: ‘enron3.tar.gz.1’\n",
            "\n",
            "enron3.tar.gz.1     100%[===================>]   4.36M  1.53MB/s    in 2.8s    \n",
            "\n",
            "2023-03-31 01:50:59 (1.53 MB/s) - ‘enron3.tar.gz.1’ saved [4569634/4569634]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron4.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4f2w7kwdJ4W",
        "outputId": "5aadd1da-8bac-4f9e-c710-4ed356da122f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 01:50:59--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron4.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2533019 (2.4M) [application/x-gzip]\n",
            "Saving to: ‘enron4.tar.gz.1’\n",
            "\n",
            "enron4.tar.gz.1     100%[===================>]   2.42M  1.13MB/s    in 2.1s    \n",
            "\n",
            "2023-03-31 01:51:01 (1.13 MB/s) - ‘enron4.tar.gz.1’ saved [2533019/2533019]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron5.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuK6pQGadQkG",
        "outputId": "496fc4b5-0751-4ba4-edbf-5620825fe8a6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 01:51:01--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron5.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2396886 (2.3M) [application/x-gzip]\n",
            "Saving to: ‘enron5.tar.gz.1’\n",
            "\n",
            "enron5.tar.gz.1     100%[===================>]   2.29M  1.01MB/s    in 2.3s    \n",
            "\n",
            "2023-03-31 01:51:03 (1.01 MB/s) - ‘enron5.tar.gz.1’ saved [2396886/2396886]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron6.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkJ68cHwdUh2",
        "outputId": "ed6a8fe7-97e5-4b5c-8033-159d99219174"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 01:51:03--  http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron6.tar.gz\n",
            "Resolving nlp.cs.aueb.gr (nlp.cs.aueb.gr)... 195.251.248.252\n",
            "Connecting to nlp.cs.aueb.gr (nlp.cs.aueb.gr)|195.251.248.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3137204 (3.0M) [application/x-gzip]\n",
            "Saving to: ‘enron6.tar.gz.1’\n",
            "\n",
            "enron6.tar.gz.1     100%[===================>]   2.99M  1.21MB/s    in 2.5s    \n",
            "\n",
            "2023-03-31 01:51:06 (1.21 MB/s) - ‘enron6.tar.gz.1’ saved [3137204/3137204]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3HqIP2OdYKQ",
        "outputId": "71d438bd-194b-411e-ff01-43a4d160bc39"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34menron1\u001b[0m/          enron2.tar.gz.1  enron4.tar.gz    \u001b[01;34menron6\u001b[0m/\n",
            "enron1.tar.gz    \u001b[01;34menron3\u001b[0m/          enron4.tar.gz.1  enron6.tar.gz\n",
            "enron1.tar.gz.1  enron3.tar.gz    \u001b[01;34menron5\u001b[0m/          enron6.tar.gz.1\n",
            "\u001b[01;34menron2\u001b[0m/          enron3.tar.gz.1  enron5.tar.gz    \u001b[01;34msample_data\u001b[0m/\n",
            "enron2.tar.gz    \u001b[01;34menron4\u001b[0m/          enron5.tar.gz.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "archivos_a_extraer = [\"enron1.tar.gz\", \"enron2.tar.gz\", \"enron3.tar.gz\", \"enron4.tar.gz\", \"enron5.tar.gz\", \"enron6.tar.gz\"]\n",
        "\n",
        "archivos_extraidos = []\n",
        "\n",
        "for archivo in archivos_a_extraer:\n",
        "    nombre_carpeta = archivo.replace(\".tar.gz\", \"\")\n",
        "    \n",
        "    if not os.path.exists(nombre_carpeta):\n",
        "        print(f\"Descomprimiendo {archivo} ...\")\n",
        "        try:\n",
        "            resultado = subprocess.run([\"tar\", \"xf\", archivo], check=True, stderr=subprocess.PIPE)\n",
        "            print(f\"{archivo} descomprimido exitosamente.\")\n",
        "            archivos_extraidos.append(archivo)\n",
        "        except subprocess.CalledProcessError as error:\n",
        "            print(f\"No se puede descomprimir {archivo}: {error.stderr.decode('utf-8').strip()}\")\n",
        "        \n",
        "        print(f\"Contenido de la carpeta actual: {os.listdir()}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"{archivo} ya ha sido extraído antes. Saltando...\")\n",
        "            \n",
        "print(\"Archivos extraídos:\")\n",
        "print(archivos_extraidos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpUr2Pg6jMCS",
        "outputId": "d2edac13-f408-4de7-dece-b09a55901c89"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enron1.tar.gz ya ha sido extraído antes. Saltando...\n",
            "enron2.tar.gz ya ha sido extraído antes. Saltando...\n",
            "enron3.tar.gz ya ha sido extraído antes. Saltando...\n",
            "enron4.tar.gz ya ha sido extraído antes. Saltando...\n",
            "enron5.tar.gz ya ha sido extraído antes. Saltando...\n",
            "enron6.tar.gz ya ha sido extraído antes. Saltando...\n",
            "Archivos extraídos:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1hIDYyEjzC-",
        "outputId": "cf611057-eced-42ee-95cd-0e09fd6106b7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34menron1\u001b[0m/          enron2.tar.gz.1  enron4.tar.gz    \u001b[01;34menron6\u001b[0m/\n",
            "enron1.tar.gz    \u001b[01;34menron3\u001b[0m/          enron4.tar.gz.1  enron6.tar.gz\n",
            "enron1.tar.gz.1  enron3.tar.gz    \u001b[01;34menron5\u001b[0m/          enron6.tar.gz.1\n",
            "\u001b[01;34menron2\u001b[0m/          enron3.tar.gz.1  enron5.tar.gz    \u001b[01;34msample_data\u001b[0m/\n",
            "enron2.tar.gz    \u001b[01;34menron4\u001b[0m/          enron5.tar.gz.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls enron1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D67dX8wKj2eJ",
        "outputId": "3a18bea3-fdaf-4899-d38a-64ce7c2f88b4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mham\u001b[0m/  \u001b[01;34mspam\u001b[0m/  \u001b[01;32mSummary.txt\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat enron1/Summary.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6EnGKiakaUB",
        "outputId": "0f13fc9e-a2ba-4c2e-e193-7b8625621890"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legitimate\r\n",
            "----------\r\n",
            "- Owner: farmer-d\r\n",
            "- Total number: 3672 emails\r\n",
            "- Date of first email: 1999-12-10\r\n",
            "- Date of last email: 2002-01-11\r\n",
            "- Similars deletion: No\r\n",
            "- Encoding: No\r\n",
            "\r\n",
            "\r\n",
            "Spam\r\n",
            "----\r\n",
            "- Owner: GP\r\n",
            "- Total number: 1500 emails\r\n",
            "- Date of first email: 2003-12-18\r\n",
            "- Date of last email: 2005-09-06\r\n",
            "- Similars deletion: No\r\n",
            "- Encoding: No\r\n",
            "\r\n",
            "Spam:Legitimate rate = 1:3\r\n",
            "Total number of emails (legitimate + spam): 5975\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import chardet\n",
        "\n",
        "data = {'subject': [], 'body': [], 'classification': []}\n",
        "\n",
        "root_dir = ''\n",
        "\n",
        "for i in range(1, 7):\n",
        "    enron_dir = os.path.join(root_dir, f'enron{i}')\n",
        "    spam_dir = os.path.join(enron_dir, 'spam')\n",
        "    ham_dir = os.path.join(enron_dir, 'ham')\n",
        "\n",
        "    for dir_path, dir_names, file_names in os.walk(spam_dir):\n",
        "        for file_name in file_names:\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                result = chardet.detect(f.read())\n",
        "                encoding = result['encoding']\n",
        "            with open(file_path, 'r', encoding=encoding, errors='ignore') as f:\n",
        "                subject = f.readline().strip()\n",
        "                body = f.read().strip()\n",
        "            data['subject'].append(subject)\n",
        "            data['body'].append(body)\n",
        "            data['classification'].append('spam')\n",
        "\n",
        "    for dir_path, dir_names, file_names in os.walk(ham_dir):\n",
        "        for file_name in file_names:\n",
        "            file_path = os.path.join(dir_path, file_name)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                result = chardet.detect(f.read())\n",
        "                encoding = result['encoding']\n",
        "            with open(file_path, 'r', encoding=encoding, errors='ignore') as f:\n",
        "                subject = f.readline().strip()\n",
        "                body = f.read().strip()\n",
        "            data['subject'].append(subject)\n",
        "            data['body'].append(body)\n",
        "            data['classification'].append('ham')\n",
        "\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "P75SrzeDkh8f"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_spam = df[df['classification'] == 'spam'].shape[0]\n",
        "num_ham = df[df['classification'] == 'ham'].shape[0]\n",
        "\n",
        "print(f'Total mensajes spam: {num_spam}')\n",
        "print(f'Total mensajes ham: {num_ham}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwXJdWVxmp31",
        "outputId": "bc8c27f5-e5b6-4059-f60d-dc47a63d161f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total mensajes spam: 17171\n",
            "Total mensajes ham: 16545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "kYXo5T8cV57w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Separar los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['body'], df['classification'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenización de palabras y creación de vectores de características\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Inicializar el modelo de Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Entrenar el modelo utilizando los datos de entrenamiento vectorizados\n",
        "nb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Evaluar el modelo utilizando los datos de prueba\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "accuracy = nb_model.score(X_test_vectorized, y_test)\n",
        "\n",
        "# Calcular la precisión del modelo\n",
        "print(f\"La precisión del modelo de Naive Bayes es de: {accuracy:.3f}\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predecir las clases de los datos de prueba\n",
        "y_pred = nb_model.predict(X_test_vectorized)\n",
        "\n",
        "# Imprimir un informe con las diferentes métricas de desempeño\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Informe de métricas de desempeño:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRFel4YQn2nY",
        "outputId": "b4c74b15-c871-49eb-bd37-87ff929f64c6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La precisión del modelo de Naive Bayes es de: 0.985\n",
            "Informe de métricas de desempeño:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.99      3374\n",
            "        spam       0.98      0.99      0.99      3370\n",
            "\n",
            "    accuracy                           0.99      6744\n",
            "   macro avg       0.99      0.99      0.99      6744\n",
            "weighted avg       0.99      0.99      0.99      6744\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "TUakTeDWV_Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "metadata": {
        "id": "1dLcc5NVqhrM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo Random Forest y entrenarlo:\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_vectorized, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "IM2J6N8pHQcR",
        "outputId": "7c4fba83-9308-49fe-bb3b-3dcb5cc318db"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer predicciones con datos de prueba\n",
        "y_pred = rf.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "d4UOcmxnIqrg"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el desempeño del modelo con varias métricas, incluyendo la precisión, matriz de confusión y reporte de clasificación:\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9jRVqJAvKG9",
        "outputId": "033c6782-a6b0-4a6c-9602-f49da85fa249"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.983540925266904\n",
            "Confusion matrix:\n",
            " [[3311   63]\n",
            " [  48 3322]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.98      3374\n",
            "        spam       0.98      0.99      0.98      3370\n",
            "\n",
            "    accuracy                           0.98      6744\n",
            "   macro avg       0.98      0.98      0.98      6744\n",
            "weighted avg       0.98      0.98      0.98      6744\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM (Support Vector Machine)"
      ],
      "metadata": {
        "id": "9at_jgj1WEt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# entrenamiento del modelo SVM\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC(kernel='linear', C=1).fit(X_train_vectorized, y_train)"
      ],
      "metadata": {
        "id": "EN35TnvovM6t"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicciones con datos de prueba\n",
        "y_pred = svc.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "LBZu7KhQwLEy"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluación del modelo\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "QcRw1KD6wtQn"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impresión de los resultados\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vgGz622ww6q",
        "outputId": "863dd5c9-f266-41fe-fadc-7a3e216fd18b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9753855278766311\n",
            "Precision: 0.9754340107687491\n",
            "Recall: 0.9753855278766311\n",
            "F1 Score: 0.9753849758447386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes neuronales (neural networks)"
      ],
      "metadata": {
        "id": "8tzsCY8fWKGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importación de librerías y funciones\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "2X0_pEH0w0MM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrenamiento del modelo MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(30,), max_iter=200, solver='adam', random_state=42).fit(X_train_vectorized, y_train)\n"
      ],
      "metadata": {
        "id": "KMNUQHwqxZEb"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicciones con datos de prueba\n",
        "y_pred = mlp.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "-MLv6YaMxehS"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluación del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "-7y8cM1azXaI"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impresión de los resultados\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXtWKkaizeMP",
        "outputId": "53525e97-c1f4-42c0-a205-c400557e64da"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.984282325029656\n",
            "Precision: 0.9842829954379672\n",
            "Recall: 0.984282325029656\n",
            "F1 Score: 0.9842823139709638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting"
      ],
      "metadata": {
        "id": "DOTP-HPNWOh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importación de librerías y funciones\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "bgTyOqSNzhm0"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrenamiento del modelo Gradient Boosting\n",
        "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42).fit(X_train_vectorized, y_train)\n"
      ],
      "metadata": {
        "id": "O6MyRtapz_EJ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicciones con datos de prueba\n",
        "y_pred = gb.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "1guaMCdQ0E9M"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluación del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "ckeJwuKz0Vof"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impresión de los resultados\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_yErsEH0YpF",
        "outputId": "1457b7e1-e410-451e-ec99-f73685a5f4c4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9457295373665481\n",
            "Precision: 0.9493845492882079\n",
            "Recall: 0.9457295373665481\n",
            "F1 Score: 0.9456204979590214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "print('Tiempo total de ejecución: {:.2f} segundos.'.format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVoJkMq48m4t",
        "outputId": "5c304a9f-4e9f-4d93-844a-47e8ee6f9a6d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo total de ejecución: 668.85 segundos.\n"
          ]
        }
      ]
    }
  ]
}